{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Para baixar os dados\n",
    "\n",
    "Primeiro, instale a versão mais recente da [API do kaggle](https://www.kaggle.com/docs/api), configure corretamente e execute o comando abaixo:\n",
    "\n",
    "```sh\n",
    "kaggle datasets download kdd2020-cpr\n",
    "```\n",
    "\n",
    "Alternativamente, o download pode ser feito diretamente a partir [dessa página](https://www.kaggle.com/maffei2443/kdd2020-cpr).\n",
    "\n",
    "Depois, basta extrair os dados para a pasta `kdd2020-cpr`.\n",
    "\n",
    "**NOTA:*** O *DATASET* utilizado neste notebook contém os mesmos dados do [*dataset* da competição][dataset], sendo a única diferença que os dados estão já agrupados por ano (um csv por ano) e há como ler os dados utilizando-se dos tipos de dados que gastam o mínimo de memória possível.\n",
    "\n",
    "[dataset]: https://www.kaggle.com/c/kddbr-2020/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import itertools    # Para as variáveis categóricas\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abaixo, alguns parâmetros \"globais\" que usamos durante a competição. Por exemplo, a constante que usamos para substituir **NaN** que apareciam nos dados (necessário já que o **MultiOutputRegressor** não aceitava dados com **NaN**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global params\n",
    "INPUT_NA = -1\n",
    "TNAME = str(datetime.datetime.now())[:-7]\n",
    "YEARS = [2018]\n",
    "OUTPUT_FILLER = 0\n",
    "QTD = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_year(y):\n",
    "    \"\"\"Loads data relative to `year` year.\n",
    "\n",
    "    Index columns is assumed to be `id` and `date` to be parseable\n",
    "    by pandas engine into a `timestamp`list.\n",
    "    \"\"\"\n",
    "    dtypes = pickle.load(open(\n",
    "        f'../input/kdd2020-cpr/{y}_dtypes.pkl', 'rb'\n",
    "    ))\n",
    "    del dtypes['date']\n",
    "    df = pd.read_csv(\n",
    "        f'../input/kdd2020-cpr/{y}.csv',\n",
    "        dtype=dtypes, parse_dates=['date'], index_col='id'\n",
    "    )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algumas features foram tomadas deste [ótimo notebook][notebook]; as demais, criadas pelo time.\n",
    "\n",
    "[notebook]: https://www.kaggle.com/adrianoavelar/kdd-starter-kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features(df):\n",
    "    \"\"\"Creates some temporal features. Assumes a `date` columns with `pd.datetime` type\n",
    "    or convertible to it.\"\"\"\n",
    "    def is_weekend(num):\n",
    "        return num > 5\n",
    "    df['date'] = pd.to_datetime( df.date )\n",
    "    dt = df['date'].dt\n",
    "    df['input_week'] = dt.week\n",
    "    df['input_weekday'] = dt.weekday + 1\n",
    "    df['input_weekday_sin'] = np.sin(2*np.pi*df.date.dt.weekday/7)    \n",
    "    df['input_weekofyear'] = dt.weekofyear\n",
    "    df['input_weekofyear_sin'] = np.sin(2*np.pi*dt.weekofyear/52)\n",
    "    df['input_weekend'] = dt.weekday.apply(is_weekend)\n",
    "    df['input_month'] = df.date.dt.month\n",
    "    df['input_year'] = df.date.dt.year\n",
    "    df['input_day'] = df.date.dt.day\n",
    "    df['input_dt_sin_quarter']     = np.sin(2*np.pi*df.date.dt.quarter/4)\n",
    "    df['input_dt_sin_day_of_week'] = np.sin(2*np.pi*df.date.dt.dayofweek/6)\n",
    "    df['input_dt_sin_day_of_year'] = np.sin(2*np.pi*df.date.dt.dayofyear/365)\n",
    "    df['input_dt_sin_day']         = np.sin(2*np.pi*df.date.dt.day/30)\n",
    "    df['input_dt_sin_month']       = np.sin(2*np.pi*df.date.dt.month/12)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carregamos os conjuntos de teste e treinamento..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = pd.concat([load_year(year) for year in YEARS])\n",
    "df_test = load_year(2019)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Faz-se a engenharia de atributos..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_features(df_test)\n",
    "create_features(base)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separamos as colunas que devem ser usadas para predição e para serem preditas..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_columns = base.columns[base.columns.str.contains('input') ]\n",
    "output_columns = base.columns[base.columns.str.contains('output') ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conjunto de treinamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = base[input_columns].fillna(INPUT_NA).values\n",
    "Y = base[output_columns].fillna(OUTPUT_FILLER).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os parêmtros que cada regressos XGB possuirá. Note-se a presença de todos os atributos que esse regressor pode receber. Entretando, a busca por melhores híperparâmetros deu-se apenas nos primeiros parâmetros listados, sendo os outros preenchidos com seu valor padrão na versão da biblioteca utilizada na competição."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PARAMS = {\n",
    " 'colsample_bylevel': .5,\n",
    " 'colsample_bynode': 0.5,\n",
    " 'colsample_bytree': 0.5,\n",
    " 'learning_rate': 0.01,\n",
    " 'max_depth': 12,\n",
    "    \n",
    " 'objective': 'reg:squarederror',\n",
    " 'base_score': 0.5,\n",
    " 'booster': 'gbtree',\n",
    " 'gamma': 0,\n",
    " 'gpu_id': 0,\n",
    " 'importance_type': 'gain',\n",
    " 'interaction_constraints': '',\n",
    " \n",
    " 'max_delta_step': 0,\n",
    " \n",
    " 'min_child_weight': 1,\n",
    " 'missing': 6358,\n",
    " 'monotone_constraints': '()',\n",
    " 'n_estimators': 1000,\n",
    " 'n_jobs': -1,\n",
    " 'num_parallel_tree': 1,\n",
    " 'random_state': 0,\n",
    " 'reg_alpha': 0,\n",
    " 'reg_lambda': 1,\n",
    " 'scale_pos_weight': 1,\n",
    " 'subsample': 0.2,\n",
    " 'tree_method': 'gpu_hist',\n",
    " 'validate_parameters': 1,\n",
    " 'verbosity': 1,\n",
    " 'sampling_method': 'gradient_based'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uma vez que o XGBoost não produz múltiplas saídas, utilizamos um *wrapper* disponibilizado pelo **sklearn** por este ser de fácil utilização. Basicamente, ele treina uma instância do modelo recebido pelo consrutor para cada variável de saída."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MultiOutputRegressor( XGBRegressor(**MODEL_PARAMS) )\n",
    "clf.fit(X[:QTD], Y[:QTD])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_columns = df_test.columns[\n",
    "    df_test.columns.str.contains('input')\n",
    "]\n",
    "df_test = df_test[input_columns].copy()\n",
    "df_test.fillna(INPUT_NA, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = clf.predict(df_test.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para efetiva submissão, era esperado que as todas as predições estivessem dispostas em duas colunas: **id** e **value**. Contudo, a primeira na verdade contém, em cada linha, três informações: um *id* do *conjunto de teste*, seguido pelo caractere `_`, concatenado com um inteiro, também seguido por `_`, concatenado com outro inteiro.  \n",
    "Esses dois inteiros representam respectivamente o número da *feature* predita (112 para cada dia) e a quantos dias no futuro se refere essa predição.  \n",
    "  \n",
    "A célula abaixo cria um *DataFrame* segundo essa lógica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_sub = pd.DataFrame(pred)\n",
    "pred_sub.columns = output_columns\n",
    "pred_sub['id'] = df_test.index\n",
    "\n",
    "submission = []\n",
    "for i, row in pred_sub.iterrows():\n",
    "    for column, value in zip(output_columns, row.values):\n",
    "        _id = \"{}_{}\".format(int(row.id), column)\n",
    "        submission.append([_id, value])\n",
    "\n",
    "\n",
    "df_sub = pd.DataFrame(submission)\n",
    "df_sub.columns = ['id', 'value']\n",
    "df_sub.set_index('id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('{}.csv'.format(TNAME), index='id')\n",
    "\n",
    "# Para submissão na última célula\n",
    "submission.to_csv('submission.csv'.format(TNAME), index='id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A céulua abaixo não tem utilidade aparente; porém, ao longo de nossos experimentos realizados no *Euler*, foi uma forma para documentarmos quais híperparâmetros produziram quais resultados. Lembrando que não foi feita uma otimização sistemática deles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"MODEL PARAMS:\", MODEL_PARAMS)\n",
    "print(\"{}.csv\".format(TNAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle competitions submit -c kddbr-2020 -f submission.csv -m \"Message\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
